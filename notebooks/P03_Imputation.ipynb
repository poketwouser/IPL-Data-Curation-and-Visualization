{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8439e862",
   "metadata": {},
   "source": [
    "# Loading Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07ff1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import import_ipynb\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbebff45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from P01_Pre_Processing import matches, trimSpaceInValues, title, latest_teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f53f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches = pd.read_csv('../data/raw/all_matches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727b77e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches = latest_teams(all_matches, ['Team 1', 'Team 2'])\n",
    "all_matches = trimSpaceInValues(all_matches)\n",
    "all_matches = title(all_matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f803cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ad8129",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71173a25",
   "metadata": {},
   "source": [
    "# Processing Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc077d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches['Time'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28858c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_time(time):\n",
    "    if pd.isna(time):\n",
    "        return None\n",
    "    time = str(time).strip().lower()\n",
    "    time = time.replace('.', '')\n",
    "    time = time.replace(' ', '')\n",
    "    time = time.replace('am', ' am').replace('pm', ' pm')\n",
    "    time = time.lstrip('0') \n",
    "    return time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e918ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches['Time'] = all_matches['Time'].apply(clean_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65529daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After careful examination, from espncricinfo.com and iplt20.com, we figured out the Matc 24 data was missing in iplt20.com data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7f785e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Create the new match row ---\n",
    "new_row = {\n",
    "    'Match': 'Match 24',\n",
    "    'Team 1': 'Chennai Super Kings',\n",
    "    'Team 2': 'Pune Warriors India',\n",
    "    'Date': pd.to_datetime('2012-04-19'),\n",
    "    'Time': '8:00 pm',\n",
    "    'Season': 2012\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3629180f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 2: Insert at index 275 ---\n",
    "before = all_matches.iloc[:275]\n",
    "after = all_matches.iloc[275:]\n",
    "all_matches = pd.concat([before, pd.DataFrame([new_row]), after], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5c97ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 3: Extract numeric match number safely ---\n",
    "all_matches['Match_Num'] = (\n",
    "    all_matches['Match']\n",
    "    .astype(str)\n",
    "    .str.extract(r'(\\d+)')[0]\n",
    ")\n",
    "all_matches['Match_Num'] = pd.to_numeric(all_matches['Match_Num'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d099f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 4: Increment match numbers for Season 2012, >= 24, but not the new row ---\n",
    "new_row_index = 275\n",
    "mask = (\n",
    "    (all_matches['Season'] == 2012) &\n",
    "    (all_matches['Match_Num'] >= 24) &\n",
    "    (all_matches.index != new_row_index)\n",
    ")\n",
    "all_matches.loc[mask, 'Match_Num'] = all_matches.loc[mask, 'Match_Num'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e748e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 5: Rebuild safely ---\n",
    "all_matches['Match_Num'] = all_matches['Match_Num'].astype('Int64')\n",
    "all_matches.loc[all_matches['Match_Num'].notna(), 'Match'] = 'Match ' + all_matches['Match_Num'].astype(str)\n",
    "all_matches.drop(columns=['Match_Num'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f78036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to rain, reserve day was used. Matches uses the scheduled date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95da8550",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches.loc[matches['Id'] == 734043, 'Date'] = pd.to_datetime('2014-05-28')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8c37ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Convert to datetime safely\n",
    "all_matches['Date'] = pd.to_datetime(all_matches['Date'], errors='coerce')\n",
    "\n",
    "# Step 2:Keep only the date part (drop the time component)\n",
    "all_matches['Date'] = all_matches['Date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c533a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(all_matches.loc[270:280])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5ec25e",
   "metadata": {},
   "source": [
    "# Concatenating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce462e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches['Date'] = pd.to_datetime(all_matches['Date'])\n",
    "all_matches['match_key'] = all_matches.apply(lambda x: tuple(sorted([x['Team 1'], x['Team 2']])), axis=1)\n",
    "all_matches.rename(columns={'Match': 'Match_No', 'Time': 'Time'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4386689c",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches['Date'] = pd.to_datetime(matches['Date'])\n",
    "matches['match_key'] = matches.apply(lambda x: tuple(sorted([x['Team1'], x['Team2']])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52525f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_match_data(all_matches = all_matches, matches = matches):\n",
    "    \"\"\"Merge both datasets using Season, Date, and team match_key.\"\"\"\n",
    "    \n",
    "    merged = pd.merge(\n",
    "        matches,\n",
    "        all_matches[['Season', 'Date', 'match_key', 'Time', 'Match_No']],\n",
    "        on=['Season', 'Date', 'match_key'],\n",
    "        how='left',\n",
    "        indicator=True\n",
    "    )\n",
    "    \n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53178809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_unmatched_rows(merged, all_matches = all_matches, matches = matches):\n",
    "    \"\"\"Find rows that didn't match in either dataset.\"\"\"\n",
    "    used_all = merged.dropna(subset=['Match_No'])[['Season', 'Date', 'match_key']]\n",
    "    \n",
    "    # Unmatched from matches\n",
    "    unmatched_matches = merged[merged['_merge'] == 'left_only']\n",
    "    \n",
    "    # Unmatched from all_matches\n",
    "    all_matches_keys = all_matches[['Season', 'Date', 'match_key']]\n",
    "    used_keys = used_all[['Season', 'Date', 'match_key']]\n",
    "    unmatched_all_matches = all_matches_keys.merge(used_keys, on=['Season', 'Date', 'match_key'], how='left', indicator=True)\n",
    "    unmatched_all_matches = unmatched_all_matches[unmatched_all_matches['_merge'] == 'left_only']\n",
    "\n",
    "    unmatched_matches = pd.DataFrame(unmatched_matches)\n",
    "    unmatched_all_matches = pd.DataFrame(unmatched_all_matches)\n",
    "    \n",
    "    return unmatched_matches, unmatched_all_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11421a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = merge_match_data(all_matches, matches)\n",
    "\n",
    "unmatched_matches, unmatched_all_matches = find_unmatched_rows(matches, all_matches, matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94d9cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"✅ Merged dataset shape:\", matches.shape)\n",
    "print(\"❌ Unmatched in matches:\", len(unmatched_matches))\n",
    "print(\"❌ Unmatched in all_matches:\", len(unmatched_all_matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2138460f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2008, 2025):\n",
    "    count = len(all_matches[all_matches['Season'] == i])\n",
    "    print(f\"{i}: {count} matches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2dcf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "unmatched_all_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23823a6",
   "metadata": {},
   "source": [
    "# Local Time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b91fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches['City'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6e5ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches['Time'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccffe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_to_offset = {\n",
    "    # India (no offset)\n",
    "    'Bangalore': 0, 'Chandigarh': 0, 'Delhi': 0, 'Mumbai': 0, 'Kolkata': 0,\n",
    "    'Jaipur': 0, 'Hyderabad': 0, 'Chennai': 0, 'Ahmedabad': 0, 'Cuttack': 0,\n",
    "    'Nagpur': 0, 'Dharamsala': 0, 'Kochi': 0, 'Indore': 0, 'Visakhapatnam': 0,\n",
    "    'Pune': 0, 'Raipur': 0, 'Ranchi': 0, 'Rajkot': 0, 'Kanpur': 0,\n",
    "    'Bengaluru': 0, 'Navi Mumbai': 0, 'Lucknow': 0, 'Guwahati': 0, 'Mohali': 0,\n",
    "\n",
    "    # South Africa (2009)\n",
    "    'Cape Town': -3.5, 'Port Elizabeth': -3.5, 'Durban': -3.5,\n",
    "    'Centurion': -3.5, 'East London': -3.5, 'Johannesburg': -3.5,\n",
    "    'Kimberley': -3.5, 'Bloemfontein': -3.5,\n",
    "\n",
    "    # UAE (2014, 2020, 2021)\n",
    "    'Abu Dhabi': -1.5, 'Dubai': -1.5, 'Sharjah': -1.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e22f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ist_to_local(time_str, city):\n",
    "    if pd.isna(time_str):\n",
    "        return None\n",
    "    \n",
    "    # normalize string\n",
    "    time_str = str(time_str).strip().lower()\n",
    "    offset = city_to_offset.get(city, 0)\n",
    "    \n",
    "    try:\n",
    "        time = datetime.strptime(time_str, \"%I:%M %p\")\n",
    "        local_t = time + timedelta(hours=offset)\n",
    "        # Use %I (zero-padded), then strip leading zeros manually for Windows compatibility\n",
    "        return local_t.strftime(\"%I:%M %p\").lstrip(\"0\").lower()\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error parsing time '{time_str}' for city '{city}': {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0440f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches['Time'] = matches.apply(lambda x: ist_to_local(x['Time'], x['City']), axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
